# ğŸ§  Offline RAG Chatbot â€“ Document Q&A System

An end-to-end **offline Retrieval-Augmented Generation (RAG) chatbot** that allows you to ask questions from your own documents without using any paid APIs.

This project uses **FAISS for vector search**, **HuggingFace embeddings for semantic understanding**, and **Ollama for local LLM inference**.

---

## ğŸš€ Features

- ğŸ“„ Upload and process PDF and text documents
- âœ‚ï¸ Intelligent document chunking for better retrieval
- ğŸ” Semantic search using FAISS vector database
- ğŸ§  Offline embeddings using HuggingFace models
- ğŸ¤– Local LLM inference using Ollama (no cloud dependency)
- ğŸ’¬ Interactive CLI chatbot interface
- ğŸ“š Source attribution for answers
- ğŸ’¸ Zero API cost â€“ fully local execution

---

## ğŸ—ï¸ Project Structure

.
â”œâ”€â”€ chat.py # Main CLI chatbot interface
â”œâ”€â”€ document_processor.py # Document loading and chunking
â”œâ”€â”€ vector_store.py # FAISS vector database management
â”œâ”€â”€ rag_pipeline.py # RAG pipeline logic
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env.example # Environment template (optional)
â”œâ”€â”€ data/ # Your documents go here
â”‚ â”œâ”€â”€ sample.txt
â”‚ â””â”€â”€ notes.pdf
â””â”€â”€ faiss_index/ # Auto-generated vector index


---

## âš™ï¸ Setup Instructions

### âœ… 1. Prerequisites

- Python 3.9+
- 8GB+ RAM recommended
- Ollama installed  
  ğŸ‘‰ https://ollama.com

---

### âœ… 2. Install Dependencies

Activate virtual environment and install packages:

```bash
pip install -r requirements.txt

âœ… 3. Pull Local LLM Model

Download a lightweight local model:

ollama pull tinyllama
ollama run tinyllama

âœ… 4. Add Your Documents

Place your documents inside the data/ folder.

Supported formats:

.txt

.pdf

.md

â–¶ï¸ Run the Chatbot
python chat.py


On first run:

Documents are loaded

Text is split into chunks

Embeddings are generated locally

FAISS vector index is created

Chat interface starts

Subsequent runs load the existing index (fast startup).

ğŸ’¬ Example Usage

Ask questions like:

What is supervised learning?

Summarize this document.

What are the main concepts discussed?

Explain key points from the PDF.

Exit anytime using:

exit
quit
Ctrl + C

ğŸ§© How It Works
ğŸ“„ Document Processing

Loads documents from data/

Splits text into overlapping chunks

Preserves semantic meaning

ğŸ“Š Vector Store (FAISS)

Converts text chunks into embeddings

Stores vectors locally

Performs fast similarity search

ğŸ” RAG Pipeline

User question received

Relevant chunks retrieved from FAISS

Context injected into prompt

Local LLM generates answer

Sources returned

ğŸ§  Local AI Stack
User Question
    â†“
FAISS Similarity Search
    â†“
Relevant Chunks
    â†“
Prompt Construction
    â†“
Ollama Local LLM
    â†“
Answer + Sources

ğŸ› ï¸ Tech Stack

Python

LangChain

FAISS

HuggingFace Embeddings

Ollama

PyPDF

NumPy

ğŸ¯ Why This Project Matters

âœ… Demonstrates real-world RAG system design

âœ… Works completely offline

âœ… No dependency on paid APIs

âœ… Strong ML + Systems engineering project

âœ… Resume-ready production-style architecture

ğŸ’¡ Future Improvements

Web UI using Streamlit / React

Multi-document summarization

Chat history memory

Hybrid search (BM25 + Vector)

GPU acceleration

Model switching support

Document metadata visualization

ğŸ“œ License

Open-source for educational and learning purposes.
